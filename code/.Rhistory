Tenyrbond <- read_csv("C://Users/manoj/Desktop/BEFD_Project_Images/Tenyrbond.csv",show_col_types = FALSE)$THREEFY10
ThreemTbill <- read_csv("C://Users/manoj/Desktop/BEFD_Project_Images/ThreemTbill.csv",show_col_types = FALSE)$DTB3
is.null(Tenyrbond)
is.null(ThreemTbill)
sum(is.na(Tenyrbond))
sum(is.na(ThreemTbill))
Tenyrbond['.' == Tenyrbond] = round(mean(as.numeric(Tenyrbond[-which('.' == Tenyrbond)])),4)
ThreemTbill['.' == ThreemTbill] = round(mean(as.numeric(ThreemTbill[-which('.' == ThreemTbill)])),4)
OVX <- read_csv("C://Users/manoj/Desktop/BEFD_Project_Images/OVX.csv",show_col_types = FALSE)$OVX
VIX <- read_csv("C://Users/manoj/Desktop/BEFD_Project_Images/VIX.csv",show_col_types = FALSE)$VIXCLS
is.null(OVX)
is.null(VIX)
sum(is.na(OVX))
sum(is.na(VIX))
OVX['.' == OVX] = round(mean(as.numeric(OVX[-which('.' == OVX)])),2)
VIX['.' == VIX] = round(mean(as.numeric(VIX[-which('.' == VIX)])),2)
Fiveyrinfexp <- read_csv("C://Users/manoj/Desktop/BEFD_Project_Images/Fiveyrinfexp.csv",show_col_types = FALSE)
dat=Fiveyrinfexp$Date
Fiveyrinfexp <- Fiveyrinfexp$T5YIE
be_inflation <- read_csv("C://Users/manoj/Desktop/BEFD_Project_Images/be_inflation.csv",show_col_types = FALSE)$T10YIE
EMV_IDT <- read_csv("C://Users/manoj/Desktop/BEFD_Project_Images/EMV_IDT.csv",show_col_types = FALSE)
EMV_IDT <- subset(EMV_IDT, EMV_IDT$Day!="Sat" & EMV_IDT$Day!="Sun")$INFECTDISEMVTRACKD
is.null(Fiveyrinfexp)
is.null(be_inflation)
is.null(EMV_IDT)
sum(is.na(Fiveyrinfexp))
sum(is.na(be_inflation))
sum(is.na(EMV_IDT))
which(is.na(EMV_IDT))
EMV_IDT[is.na(EMV_IDT)] <- mean(EMV_IDT, na.rm = TRUE)
Fiveyrinfexp['.' == Fiveyrinfexp] = round(mean(as.numeric(Fiveyrinfexp[-which('.' == Fiveyrinfexp)])),2)
be_inflation['.' == be_inflation] = round(mean(as.numeric(be_inflation[-which('.' == be_inflation)])),2)
final_df = data.frame(dat,btc.xts$Open,btc.xts$High,btc.xts$Low,btc.xts$Close,btc.xts$Adjusted,btc.xts$Volume,rsi,StoFASTK,StoFASTD,StoSLOWK,adx,roc,obv,mfi,ad,MA50,MA200,MACD,MACDSignal,EPU,EMU,Tenyrbond,ThreemTbill,OVX,VIX,Fiveyrinfexp,be_inflation,EMV_IDT)
head(final_df)
new_df <- final_df[50:1282,-c(18)]
#new_df <- cbind(row_names = row.names(new_df), new_df)
rownames(new_df) <- c(1:1233)
colnames(new_df)[1] <- "Date"
# Convert Tenyrbond,ThreemTbill,OVX,VIX, Fiveyrinfexp,be_inflation from char to numeric
new_df$Tenyrbond <- as.numeric(new_df$Tenyrbond)
new_df$ThreemTbill <- as.numeric(new_df$ThreemTbill)
new_df$OVX <- as.numeric(new_df$OVX)
new_df$VIX <- as.numeric(new_df$VIX)
new_df$Fiveyrinfexp <- as.numeric(new_df$Fiveyrinfexp)
new_df$be_inflation  <- as.numeric(new_df$be_inflation )
head(new_df)
#Check which column has NA values in the dataframe
# Load the dplyr package
library(dplyr)
# Count the number of missing values in each column
missing_counts <- colSums(is.na(new_df))
# Print the number of missing values in each column
print(missing_counts)
new_df <- na.omit(new_df)
library(dplyr)
new_df1 = select(new_df, -c(2,3,4,5,7,'ad'))
col_names <- names(new_df1)
col_names[2] <- "Price"
col_names[3] <- "RSI"
col_names[9] <- "OBV"
col_names[11] <- "MA_50"
col_names[13] <- "MACDSignal"
names(new_df1) <- col_names
#new_df1$index <- as.numeric(row.names(new_df1))
#new_df1[order(new_df1$index),]
library(gbm)
boost.model=gbm(Price ~ . ,data=new_df1[,2:22],
distribution="gaussian",n.trees=5000, interaction.depth=8, shrinkage=0.01)
# default vector of parameters
mai.old<-par()$mai
mai.old
#new vector
mai.new<-mai.old
#new space on the left
mai.new[2] <- 2.5
mai.new
#modify graphical parameters
par(mai=mai.new)
#relative influence plot
summary(boost.model, las=1, cBar=10)
#cBar defines how many variables
#back to orginal window
par(mai=mai.old)
final_df = new_df1[,c('Date','Price','MA_50','OBV','ThreemTbill','RSI','Tenyrbond','MACDSignal','mfi','macd','be_inflation','OVX')]
write.csv(final_df,"C://Users/manoj/Desktop/BEFD_Project_Images/df.csv")
final_df = new_df1[,c('Date','Price','MA_50','OBV','ThreemTbill','RSI','Tenyrbond','MACDSignal','mfi','macd','be_inflation','OVX')]
write.csv(final_df,"C://Users/manoj/Desktop/BEFD_Project_Images/df.csv")
library(stats)
# Convert the data to a time series object
ts_data_train <- ts(final_df$Price[2:1222], frequency = 5)
ts_data_test <- ts(final_df$Price[1222:1232], frequency = 5)
ts_data <- ts(final_df$Price[2:1232], frequency = 5)
# Decompose the time series using the stl function
stl_decomposition <- stl(ts_data_train, s.window = "periodic")
# Extract the seasonality, trend, and remainder components
seasonality <- stl_decomposition$time.series[, 1]
trend <- stl_decomposition$time.series[, 2]
remainder <- stl_decomposition$time.series[, 3]
#acf(new_df1$Price, lag.max=34)
# Plot the seasonality, trend, and remainder components
plot(seasonality, main = "Seasonality")
plot(trend, main = "Trend")
plot(remainder, main = "Remainder")
#pice <- btc.xts$Adjusted
model = auto.arima(ts_data_train)
res <- residuals(model)
Acf(res)
fitted(model)
# Set the number of rows and columns of plots
par(mfrow=c(1, 1))
plot(ts_data_train, col="red",type ='b', xlab = 'Day',ylab="BTC price", pch=16, lty=3,cex=0.6)
mtext("09/02/2018 to 14/10/2022", side=3, line=1)
lines(fitted(model),col="blue")
predictions <- forecast(model, h=10)
AIC(model)
final_df <- as.data.frame(scale(final_df))
#transform release_date in numeric
final_df$Date<-as.numeric(final_df$Date)
summary(final_df$Date)
final_df <- as.data.frame(scale(final_df))
#transform release_date in numeric
final_df$Date<-as.numeric(final_df$Date)
summary(final_df$Date)
#import the libraries we need
library(jsonlite)
library(glue)
library(readr)
library(lmtest)
library(forecast)
library(DIMORA)
library(ggplot2)
library(quantmod)
library(TTR) # Technical Trading Rules
btc <- read_csv("M://Crypto_Analysis/BTC-USD.csv", show_col_types = FALSE)
eth <- read_csv("M://Crypto_Analysis/ETH-USD.csv", show_col_types = FALSE)
btc1 <- read_csv("M://Crypto_Analysis/BTC-USD-1.csv", show_col_types = FALSE)
btc
eth
btc
eth
for_date <- function(x){
return(as.Date(as.POSIXct(strptime(x,"%d/%m/%Y"))))
}
mod_date= lapply(btc[2:1796,1],for_date)
btc.xts <- xts(btc[1:1795,2:8],order.by=mod_date$Date)
btc.xts <- subset(btc.xts, btc.xts$Weekday!=6 & btc.xts$Weekday!=7)
#man.xts <- subset(btc.xts$Adjusted, man.xts$Weekday!=6 & btc.xts$Weekday!=7)
#n.xts <- man.xts[,2]
btc <- subset(btc, btc$Weekday!=6 & btc$Weekday!=7)
eth <- subset(eth, eth$Day!="Sat" & eth$Day!="Sun")
rsi <- RSI(Cl(btc.xts),n=14)
barChart(btc.xts,theme=chartTheme("white"))
addRSI(n=14)
stochOSC <-stoch(btc.xts[,c("High","Low","Close")],nFastK = 14,
nFastD = 3,
nSlowD = 3,)
StoFASTK = stochOSC$fastK
StoFASTD = stochOSC$fastD
StoSLOWK = stochOSC$slowD
tail(stochOSC,10)
plot(tail(stochOSC[,"fastK"], 100), type="l",
main="Fast %K ", ylab="")
adx <- ADX(btc.xts[,c("High","Low","Close")])$ADX
tail(adx,10)
plot(tail(adx, 100), type="l",
main="Average Directional Index ", ylab="")
roc <- ROC(btc.xts[,"Close"])
tail(roc,n=3)
obv <- OBV(btc.xts[,"Close"], btc.xts[,"Volume"])
tail(obv,n=3)
mfi <- MFI(btc.xts[,"Close"], btc.xts[,"Volume"], n =14)
tail(mfi,n=3)
ad <- williamsAD(btc.xts[,c("High","Low","Close")])
tail(ad,n=3)
MA50 <-SMA(Cl(btc.xts),n=50)
MA200 <-SMA(Cl(btc.xts),n=200)
tail(MA50,n=3)
tail(MA200,n=3)
macd <- MACD(Cl(btc.xts), nFast=14, nSlow=3,
nSig=9, percent=FALSE)
MACD <- macd$macd
MACDSignal <- macd$signal
tail(macd,n=5)
plot(tail(MACD, 100), type="l",
main="MACD AND MOVING AVGS.", ylab="")
lines(MACDSignal, lwd=2, col=2)
lines(MA50, lwd=2, col=3)
lines(MA200, lwd=2, col=4)
EPU <- read_csv("C://Users/manoj/Desktop/BEFD_Project_Images/EPU.csv",show_col_types = FALSE)
EMU <- read_csv("C://Users/manoj/Desktop/BEFD_Project_Images/EMU.csv",show_col_types = FALSE)
EPU <- subset(EPU, EPU$Day!="Sat" & EPU$Day!="Sun")$USEPUINDXD
EMU <- subset(EMU, EMU$Day!="Sat" & EMU$Day!="Sun")$WLEMUINDXD
is.null(EPU)
is.null(EMU)
sum(is.na(EPU))
sum(is.na(EMU))
Tenyrbond <- read_csv("C://Users/manoj/Desktop/BEFD_Project_Images/Tenyrbond.csv",show_col_types = FALSE)$THREEFY10
ThreemTbill <- read_csv("C://Users/manoj/Desktop/BEFD_Project_Images/ThreemTbill.csv",show_col_types = FALSE)$DTB3
is.null(Tenyrbond)
is.null(ThreemTbill)
sum(is.na(Tenyrbond))
sum(is.na(ThreemTbill))
Tenyrbond['.' == Tenyrbond] = round(mean(as.numeric(Tenyrbond[-which('.' == Tenyrbond)])),4)
ThreemTbill['.' == ThreemTbill] = round(mean(as.numeric(ThreemTbill[-which('.' == ThreemTbill)])),4)
OVX <- read_csv("C://Users/manoj/Desktop/BEFD_Project_Images/OVX.csv",show_col_types = FALSE)$OVX
VIX <- read_csv("C://Users/manoj/Desktop/BEFD_Project_Images/VIX.csv",show_col_types = FALSE)$VIXCLS
is.null(OVX)
is.null(VIX)
sum(is.na(OVX))
sum(is.na(VIX))
OVX['.' == OVX] = round(mean(as.numeric(OVX[-which('.' == OVX)])),2)
VIX['.' == VIX] = round(mean(as.numeric(VIX[-which('.' == VIX)])),2)
Fiveyrinfexp <- read_csv("C://Users/manoj/Desktop/BEFD_Project_Images/Fiveyrinfexp.csv",show_col_types = FALSE)
dat=Fiveyrinfexp$Date
Fiveyrinfexp <- Fiveyrinfexp$T5YIE
be_inflation <- read_csv("C://Users/manoj/Desktop/BEFD_Project_Images/be_inflation.csv",show_col_types = FALSE)$T10YIE
EMV_IDT <- read_csv("C://Users/manoj/Desktop/BEFD_Project_Images/EMV_IDT.csv",show_col_types = FALSE)
EMV_IDT <- subset(EMV_IDT, EMV_IDT$Day!="Sat" & EMV_IDT$Day!="Sun")$INFECTDISEMVTRACKD
is.null(Fiveyrinfexp)
is.null(be_inflation)
is.null(EMV_IDT)
sum(is.na(Fiveyrinfexp))
sum(is.na(be_inflation))
sum(is.na(EMV_IDT))
which(is.na(EMV_IDT))
EMV_IDT[is.na(EMV_IDT)] <- mean(EMV_IDT, na.rm = TRUE)
Fiveyrinfexp['.' == Fiveyrinfexp] = round(mean(as.numeric(Fiveyrinfexp[-which('.' == Fiveyrinfexp)])),2)
be_inflation['.' == be_inflation] = round(mean(as.numeric(be_inflation[-which('.' == be_inflation)])),2)
final_df = data.frame(dat,btc.xts$Open,btc.xts$High,btc.xts$Low,btc.xts$Close,btc.xts$Adjusted,btc.xts$Volume,rsi,StoFASTK,StoFASTD,StoSLOWK,adx,roc,obv,mfi,ad,MA50,MA200,MACD,MACDSignal,EPU,EMU,Tenyrbond,ThreemTbill,OVX,VIX,Fiveyrinfexp,be_inflation,EMV_IDT)
head(final_df)
#Execute below code if you want to save final df as csv file.
#write.csv(final_df,"C://Users/manoj/Desktop/BEFD_Project_Images/Final_df.csv")
new_df <- final_df[50:1282,-c(18)]
#new_df <- cbind(row_names = row.names(new_df), new_df)
rownames(new_df) <- c(1:1233)
colnames(new_df)[1] <- "Date"
# Convert Tenyrbond,ThreemTbill,OVX,VIX, Fiveyrinfexp,be_inflation from char to numeric
new_df$Tenyrbond <- as.numeric(new_df$Tenyrbond)
new_df$ThreemTbill <- as.numeric(new_df$ThreemTbill)
new_df$OVX <- as.numeric(new_df$OVX)
new_df$VIX <- as.numeric(new_df$VIX)
new_df$Fiveyrinfexp <- as.numeric(new_df$Fiveyrinfexp)
new_df$be_inflation  <- as.numeric(new_df$be_inflation )
head(new_df)
#Check which column has NA values in the dataframe
# Load the dplyr package
library(dplyr)
# Count the number of missing values in each column
missing_counts <- colSums(is.na(new_df))
# Print the number of missing values in each column
print(missing_counts)
new_df <- na.omit(new_df)
library(dplyr)
new_df1 = select(new_df, -c(2,3,4,5,7,'ad'))
col_names <- names(new_df1)
col_names[2] <- "Price"
col_names[3] <- "RSI"
col_names[9] <- "OBV"
col_names[11] <- "MA_50"
col_names[13] <- "MACDSignal"
names(new_df1) <- col_names
#new_df1$index <- as.numeric(row.names(new_df1))
#new_df1[order(new_df1$index),]
library(gbm)
boost.model=gbm(Price ~ . ,data=new_df1[,2:22],
distribution="gaussian",n.trees=5000, interaction.depth=8, shrinkage=0.01)
# default vector of parameters
mai.old<-par()$mai
mai.old
#new vector
mai.new<-mai.old
#new space on the left
mai.new[2] <- 2.5
mai.new
#modify graphical parameters
par(mai=mai.new)
#relative influence plot
summary(boost.model, las=1, cBar=10)
#cBar defines how many variables
#back to orginal window
par(mai=mai.old)
final_df = new_df1[,c('Date','Price','MA_50','OBV','ThreemTbill','RSI','Tenyrbond','MACDSignal','mfi','macd','be_inflation','OVX')]
write.csv(final_df,"C://Users/manoj/Desktop/BEFD_Project_Images/df.csv")
plot(new_df1$Price)
library(stats)
# Convert the data to a time series object
ts_data_train <- ts(final_df$Price[2:1222], frequency = 5)
ts_data_test <- ts(final_df$Price[1222:1232], frequency = 5)
ts_data <- ts(final_df$Price[2:1232], frequency = 5)
# Decompose the time series using the stl function
stl_decomposition <- stl(ts_data_train, s.window = "periodic")
# Extract the seasonality, trend, and remainder components
seasonality <- stl_decomposition$time.series[, 1]
trend <- stl_decomposition$time.series[, 2]
remainder <- stl_decomposition$time.series[, 3]
#acf(new_df1$Price, lag.max=34)
library(tseries)
adf.test(ts_data)
# Plot the seasonality, trend, and remainder components
plot(seasonality, main = "Seasonality")
plot(trend, main = "Trend")
plot(remainder, main = "Remainder")
#pice <- btc.xts$Adjusted
model = auto.arima(ts_data_train)
res <- residuals(model)
Acf(res)
fitted(model)
# Set the number of rows and columns of plots
par(mfrow=c(1, 1))
plot(ts_data_train, col="red",type ='b', xlab = 'Day',ylab="BTC price", pch=16, lty=3,cex=0.6)
mtext("09/02/2018 to 14/10/2022", side=3, line=1)
lines(fitted(model),col="blue")
predictions <- forecast(model, h=10)
x <- 1:10
plot(x, ts_data_test[1:10], col="blue",type ='b', xlab = 'Day',ylab="BTC price", pch=16, lty=3,cex=0.6)
mtext("Forecast from 14/10/2022 to 24/10/2022", side=3, line=1)
lines(x, predictions$mean, col='red',xaxt='n')
AIC(model)
# Calculate the absolute percentage error for each data point
errors <- abs((predictions - actuals) / actuals)
#transform release_date in numeric
final_df$Date<-as.numeric(final_df$Date)
summary(final_df$Date)
final_df$Date <- as.Date(final_df$Date, "%d/%m/%Y")
final_df = new_df1[,c('Date','Price','MA_50','OBV','ThreemTbill','RSI','Tenyrbond','MACDSignal','mfi','macd','be_inflation','OVX')]
write.csv(final_df,"C://Users/manoj/Desktop/BEFD_Project_Images/df.csv")
final_df$Date <- as.Date(final_df$Date, "%d/%m/%Y")
str(final_df)
#transform release_date in numeric
final_df$Date<-as.numeric(final_df$Date)
summary(final_df$Date)
# Set train and test
set.seed(1)
train = sample (1:nrow(final_df), 0.7*nrow(final_df))
final_df.train=final_df[train ,]
final_df.test=final_df[-train ,]
#pice <- btc.xts$Adjusted
model = auto.arima(final_df.train)
library(stats)
# Convert the data to a time series object
ts_data_train <- ts(final_df$Price[2:1222], frequency = 5)
ts_data_test <- ts(final_df$Price[1222:1232], frequency = 5)
ts_data <- ts(final_df$Price[2:1232], frequency = 5)
# Decompose the time series using the stl function
stl_decomposition <- stl(ts_data_train, s.window = "periodic")
# Extract the seasonality, trend, and remainder components
seasonality <- stl_decomposition$time.series[, 1]
trend <- stl_decomposition$time.series[, 2]
remainder <- stl_decomposition$time.series[, 3]
#acf(new_df1$Price, lag.max=34)
# Plot the seasonality, trend, and remainder components
plot(seasonality, main = "Seasonality")
plot(trend, main = "Trend")
plot(remainder, main = "Remainder")
#pice <- btc.xts$Adjusted
model = auto.arima(ts_data_train)
res <- residuals(model)
Acf(res)
fitted(model)
# Set the number of rows and columns of plots
par(mfrow=c(1, 1))
plot(ts_data_train, col="red",type ='b', xlab = 'Day',ylab="BTC price", pch=16, lty=3,cex=0.6)
mtext("09/02/2018 to 14/10/2022", side=3, line=1)
lines(fitted(model),col="blue")
predictions <- forecast(model, h=10)
x <- 1:10
plot(x, ts_data_test[1:10], col="blue",type ='b', xlab = 'Day',ylab="BTC price", pch=16, lty=3,cex=0.6)
mtext("Forecast from 14/10/2022 to 24/10/2022", side=3, line=1)
lines(x, predictions$mean, col='red',xaxt='n')
AIC(model)
# Calculate the absolute percentage error for each data point
errors <- abs((predictions - ts_data_test) / actuals)
AIC(model)
# Calculate the absolute percentage error for each data point
errors <- abs((predictions - ts_data_test) / ts_data_test)
predictions
AIC(model)
# Calculate the absolute percentage error for each data point
errors <- abs((predictions$mean - ts_data_test) / ts_data_test)
predictions$mean
ts_data_test
x <- 1:10
plot(x, ts_data_test[1:11], col="blue",type ='b', xlab = 'Day',ylab="BTC price", pch=16, lty=3,cex=0.6)
x <- 1:11
plot(x, ts_data_test[1:11], col="blue",type ='b', xlab = 'Day',ylab="BTC price", pch=16, lty=3,cex=0.6)
mtext("Forecast from 14/10/2022 to 24/10/2022", side=3, line=1)
lines(x, predictions$mean, col='red',xaxt='n')
x <- 1:10
plot(x, ts_data_test[1:10], col="blue",type ='b', xlab = 'Day',ylab="BTC price", pch=16, lty=3,cex=0.6)
mtext("Forecast from 14/10/2022 to 24/10/2022", side=3, line=1)
lines(x, predictions$mean, col='red',xaxt='n')
AIC(model)
# Calculate the absolute percentage error for each data point
errors <- abs((predictions$mean - ts_data_test[1:10]) / ts_data_test[1:10])
# Calculate the mean absolute percentage error
mape <- mean(errors) * 100
# Print the result
print(mape)
AIC(model)
# Calculate the absolute percentage error for each data point
errors <- abs((predictions$mean - ts_data_test[1:10]) / ts_data_test[1:10])
# Calculate the mean absolute percentage error
mape <- mean(errors) * 100
# Print the result
print(mape)
# Calculate the squared error for each data point
squared_errors <- (predictions$mean - ts_data_test[1:10])^2
# Calculate the mean squared error
mse <- mean(squared_errors)
# Take the square root of the mean squared error
rmse <- sqrt(mse)
# Print the result
print(rmse)
AIC(model)
# Calculate the absolute percentage error for each data point
errors <- abs((predictions$mean - ts_data_test[1:10]) / ts_data_test[1:10])
# Calculate the mean absolute percentage error
mape <- mean(errors) * 100
# Print the result
print(mape)
# Calculate the squared error for each data point
squared_errors <- (predictions$mean - ts_data_test[1:10])^2
# Calculate the mean squared error
mse <- mean(squared_errors)
# Take the square root of the mean squared error
rmse <- sqrt(mse)
# Print the result
print(rmse)
AIC(model)
# Calculate the absolute percentage error for each data point
errors <- abs((predictions$mean - ts_data_test[1:10]) / ts_data_test[1:10])
# Calculate the mean absolute percentage error
mape <- mean(errors) * 100
# Print the result
print(mape)
# Calculate the squared error for each data point
squared_errors <- (predictions$mean - ts_data_test[1:10])^2
# Calculate the mean squared error
mse <- mean(squared_errors)
# Take the square root of the mean squared error
rmse <- sqrt(mse)
# Print the result
print(rmse)
AIC(model)
# Calculate the absolute percentage error for each data point
errors <- abs((predictions$mean - ts_data_test[1:10]) / ts_data_test[1:10])
# Calculate the mean absolute percentage error
mape <- mean(errors) * 100
# Print the result
print(mape)
# Calculate the squared error for each data point
squared_errors <- (predictions$mean - ts_data_test[1:10])^2
# Calculate the mean squared error
mse <- mean(squared_errors)
# Take the square root of the mean squared error
rmse <- sqrt(mse)
# Print the result
print(rmse)
predictions <- forecast(model, h=10)
x <- 1:10
plot(x, ts_data_test[1:10], col="blue",type ='b', xlab = 'Day',ylab="BTC price", pch=16, lty=3,cex=0.6)
mtext("Forecast from 14/10/2022 to 24/10/2022", side=3, line=1)
lines(x, predictions$mean, col='red',xaxt='n')
AIC(model)
# Calculate the absolute percentage error for each data point
errors <- abs((predictions$mean - ts_data_test[1:10]) / ts_data_test[1:10])
# Calculate the mean absolute percentage error
mape <- mean(errors) * 100
# Print the result
print(mape)
# Calculate the squared error for each data point
squared_errors <- (predictions$mean - ts_data_test[1:10])^2
# Calculate the mean squared error
mse <- mean(squared_errors)
# Take the square root of the mean squared error
rmse <- sqrt(mse)
# Print the result
print(rmse)
# plotting time-series object
#ts.plot(btc.price.ts, type="l", col="red")
ts.plot(ts_data_train, col="black",xlab= "Week",ylab='Price')
# fitting linear model on time-series object with just trend
fit.t <- tslm(ts_data_trian~trend)
# plotting time-series object
#ts.plot(btc.price.ts, type="l", col="red")
ts.plot(ts_data_train, col="black",xlab= "Week",ylab='Price')
# fitting linear model on time-series object with just trend
fit.t <- tslm(ts_data_train~trend)
summary(fit.t)
# plotting time-series regression line
ts.plot(ts_data, xlab="Week", ylab="BTC price", main="Plotting time-series regression line of BTC prices over time", col=2)
lines(fitted(fit.t), col=1)
##check the residuals if they are auto-correlated by using Durbin Watson test
dwtest(fit.t)
AIC(fit.t)
forecast(fit.t, h=10)
tslmf= forecast(fit.t, h=10)
AIC(fit.t)
# Calculate the absolute percentage error for each data point
errors <- abs((tslmf$mean - ts_data_test[1:10]) / ts_data_test[1:10])
# Calculate the mean absolute percentage error
mape <- mean(errors) * 100
# Print the result
print(mape)
# Calculate the squared error for each data point
squared_errors <- (tslmf$mean - ts_data_test[1:10])^2
# Calculate the mean squared error
mse <- mean(squared_errors)
# Take the square root of the mean squared error
rmse <- sqrt(mse)
# Print the result
print(rmse)
